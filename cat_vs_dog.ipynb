{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "authorship_tag": "ABX9TyM7OWZUNqShgGUU3TqiA+Sg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uwanggood/colab/blob/main/cat_vs_dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLkpO8GLsg-r",
        "outputId": "2ddef5b4-14b3-4633-b4a1-6d0c60e95df0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr_1wWADtXPp",
        "outputId": "79331810-8499-4350-b407-58776a1aa4fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Dataset/dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA8eJdDgteIp",
        "outputId": "a6f09a7d-71b6-48a3-b551-8dcd59eaef8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dataset/dogs-vs-cats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "id": "sZj-UnfD8zRg",
        "outputId": "94b67c99-ea40-4227-ad80-2152a8fff924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1ff02af6-3774-400b-9353-e00c76a03961\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1ff02af6-3774-400b-9353-e00c76a03961\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"jaesangsong\",\"key\":\"225f605d242cec94076d2a1867063334\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "X51W-ahw9apD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "KcEelUa29fXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "N_CKF7Sh9iBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-pLWcmM9mxJ",
        "outputId": "5597df03-6992-43fe-8e0c-14d060d56476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                            title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "-------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "iamsouravbanerjee/world-population-dataset                     World Population Dataset                             17KB  2022-08-31 11:20:04           6297        201  1.0              \n",
            "kaggleashwin/population-dataset                                World Population by Countries Dataset (1960-2021)    69KB  2022-08-31 05:30:26           1661         71  1.0              \n",
            "iamsouravbanerjee/house-rent-prediction-dataset                House Rent Prediction Dataset                        82KB  2022-08-20 13:49:03          12253        309  1.0              \n",
            "pantanjali/unemployment-dataset                                Unemployment dataset                                 17KB  2022-09-08 08:26:10           1277         44  1.0              \n",
            "ariyoomotade/netflix-data-cleaning-analysis-and-visualization  Netflix Data: Cleaning, Analysis and Visualization  270KB  2022-08-26 09:25:43           3695         91  1.0              \n",
            "rohitmahulkar/online-retails-sale-dataset                      Online Retails Sale Dataset                           8MB  2022-08-25 18:04:52           1071         27  0.9411765        \n",
            "deepcontractor/smoke-detection-dataset                         Smoke Detection Dataset                               2MB  2022-08-21 06:29:34           2333         80  1.0              \n",
            "estienneggx/spotify-unpopular-songs                            Spotify unpopular songs                             737KB  2022-09-04 22:10:41            979         38  1.0              \n",
            "evangower/chocolate-bar-ratings                                Chocolate Bar Ratings                                64KB  2022-09-06 15:37:56            573         33  1.0              \n",
            "sveta151/tiktok-popular-songs-2020                             TikTok popular songs 2020                            17KB  2022-08-22 10:49:13            715         28  1.0              \n",
            "arianazmoudeh/airbnbopendata                                   Airbnb Open Data                                     10MB  2022-08-01 15:58:10           4637        125  0.9705882        \n",
            "totoro29/imdb-movies                                           IMDB Movies                                         668KB  2022-08-22 13:43:25            657         30  0.9411765        \n",
            "samuelcortinhas/gdp-of-european-countries                      GDP of European countries                            795B  2022-09-01 13:15:51            381         31  1.0              \n",
            "advaypatil/youtube-statistics                                  Youtube Statistics                                    2MB  2022-08-26 02:03:19           1395         52  1.0              \n",
            "sveta151/spotify-top-chart-songs-2022                          Spotify top chart songs 2022                         45KB  2022-09-05 07:59:27            719         36  1.0              \n",
            "sveta151/tiktok-popular-songs-2021                             TikTok popular songs 2021                            11KB  2022-08-22 11:02:34            987         36  1.0              \n",
            "yasirabdaali/corona-virus-covid19-us-counties                  Corona Virus Covid-19  US Counties                   75MB  2022-08-22 02:38:55            638         26  0.9411765        \n",
            "surajjha101/fortune-top-1000-companies-by-revenue-2022         Fortune Top 1000 Companies by Revenue 2022           37KB  2022-08-28 06:43:27            973         49  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                          Melbourne Housing Snapshot                          451KB  2018-06-05 12:52:24          95438       1137  0.7058824        \n",
            "zwl1234/top-50-bestselling-novels-20092021-of-amazon           Top 50 Bestselling Novels 2009-2021 of Amazon        36KB  2022-08-29 15:50:47           1150         31  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle kernels output uysimty/keras-cnn-dog-or-cat-classification -p /content/drive/MyDrive/Dataset/dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT-addIz9psZ",
        "outputId": "27e69770-786a-4096-d770-362798804bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output file downloaded to /content/drive/MyDrive/Dataset/dogs-vs-cats/model.h5\n",
            "Output file downloaded to /content/drive/MyDrive/Dataset/dogs-vs-cats/submission.csv\n",
            "Kernel log downloaded to /content/drive/MyDrive/Dataset/dogs-vs-cats/keras-cnn-dog-or-cat-classification.log \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-sSSzNm9-6M",
        "outputId": "55afe4ff-db88-41e9-f53e-717c0ace9b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content/drive/MyDrive/Dataset/dogs-vs-cats\n",
            "100% 809M/812M [00:13<00:00, 63.4MB/s]\n",
            "100% 812M/812M [00:13<00:00, 61.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip dogs-vs-cats.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb7d2vK5-ZyV",
        "outputId": "a1125e17-bd16-473c-cc11-f03ce874f248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dogs-vs-cats.zip\n",
            "  inflating: sampleSubmission.csv    \n",
            "  inflating: test1.zip               \n",
            "  inflating: train.zip               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip test1.zip"
      ],
      "metadata": {
        "id": "00P1N3OB-35K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip train.zip"
      ],
      "metadata": {
        "id": "eH4AFfBT_vwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/workspace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3i5HhCIIesi",
        "outputId": "570c9db6-527e-4667-8b60-ce926ef212dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/workspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Uwanggood/titanic_project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcKa4M6wNfpe",
        "outputId": "be5a72ee-11c1-41b1-f268-1636bca86009"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'titanic_project'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 76 (delta 30), reused 58 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (76/76), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd titanic_project/src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt7MR90pN7TP",
        "outputId": "13ad5681-5aeb-4cb8-b96b-c64faaef287f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/workspace/titanic_project/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset's setting is over "
      ],
      "metadata": {
        "id": "2LUHk5Z_-dev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python catVSdog_study.py --data_dir /content/drive/MyDrive/Dataset/dogs-vs-cats "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZR_kndHPC-G",
        "outputId": "f56d2446-ac46-4f3e-c212-10b07d5ac4e4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train', 'sampleSubmission.csv', 'test1.zip', 'train.zip', 'kaggle.json', 'model.h5', 'submission.csv', 'keras-cnn-dog-or-cat-classification.log', 'dogs-vs-cats.zip', 'test1']\n",
            "Figure(640x480)\n",
            "2022-09-16 17:00:09.140384: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 126, 126, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 63, 63, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 61, 61, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 28, 28, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,942,786\n",
            "Trainable params: 12,941,314\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Found 13968 validated image filenames belonging to 2 classes.\n",
            "Found 3492 validated image filenames belonging to 2 classes.\n",
            "Found 1 validated image filenames belonging to 1 classes.\n",
            "catVSdog_study.py:171: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  callbacks=callbacks\n",
            "Epoch 1/50\n",
            "931/931 [==============================] - ETA: 0s - loss: 0.7213 - accuracy: 0.6878Traceback (most recent call last):\n",
            "  File \"catVSdog_study.py\", line 254, in <module>\n",
            "    main(opt)\n",
            "  File \"catVSdog_study.py\", line 249, in main\n",
            "    run(**vars(opt))\n",
            "  File \"catVSdog_study.py\", line 171, in run\n",
            "    callbacks=callbacks\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 2223, in fit_generator\n",
            "    initial_epoch=initial_epoch)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 55, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
            "\n",
            "Detected at node 'sequential/flatten/Reshape' defined at (most recent call last):\n",
            "    File \"catVSdog_study.py\", line 254, in <module>\n",
            "      main(opt)\n",
            "    File \"catVSdog_study.py\", line 249, in main\n",
            "      run(**vars(opt))\n",
            "    File \"catVSdog_study.py\", line 171, in run\n",
            "      callbacks=callbacks\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 2223, in fit_generator\n",
            "      initial_epoch=initial_epoch)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1431, in fit\n",
            "      _use_cached_eval_dataset=True)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1716, in evaluate\n",
            "      tmp_logs = self.test_function(iterator)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1525, in test_function\n",
            "      return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1514, in step_function\n",
            "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1507, in run_step\n",
            "      outputs = model.test_step(data)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1471, in test_step\n",
            "      y_pred = self(x, training=False)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
            "      outputs = call_fn(inputs, *args, **kwargs)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\", line 374, in call\n",
            "      return super(Sequential, self).call(inputs, training=training, mask=mask)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n",
            "      inputs, training=training, mask=mask)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n",
            "      outputs = node.layer(*args, **kwargs)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n",
            "      outputs = call_fn(inputs, *args, **kwargs)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/core/flatten.py\", line 96, in call\n",
            "      return tf.reshape(inputs, flattened_shape)\n",
            "Node: 'sequential/flatten/Reshape'\n",
            "Input to reshape is a tensor with 1728000 values, but the requested shape requires a multiple of 25088\n",
            "\t [[{{node sequential/flatten/Reshape}}]] [Op:__inference_test_function_5950]\n",
            "2022-09-16 17:08:40.523293: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: FAILED_PRECONDITION: Python interpreter state is not initialized. The process may be terminated.\n",
            "\t [[{{node PyFunc}}]]\n",
            "2022-09-16 17:08:40.525045: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: FAILED_PRECONDITION: Python interpreter state is not initialized. The process may be terminated.\n",
            "\t [[{{node PyFunc}}]]\n"
          ]
        }
      ]
    }
  ]
}